{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Network Analysis with BigQuery\n",
                "## Bachelor Thesis Data Analysis\n",
                "\n",
                "This notebook contains templates and utilities for analyzing social network data stored in BigQuery."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Enable inline plotting\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Current credentials path: /Users/calvindudek/projects/sophie/twitter-analysis-python/.secrets/service-account.json\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "\n",
                "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/calvindudek/projects/sophie/twitter-analysis-python/.secrets/service-account.json'\n",
                "\n",
                "creds_path = os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
                "print(f\"Current credentials path: {creds_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Configuration\n",
                "\n",
                "Import libraries and set up BigQuery connections."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data handling and analysis\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from datetime import datetime, timedelta\n",
                "\n",
                "# BigQuery\n",
                "from google.cloud import bigquery\n",
                "from google.cloud.exceptions import GoogleCloudError\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import matplotlib.dates as mdates\n",
                "from matplotlib.colors import LinearSegmentedColormap\n",
                "\n",
                "# Configure plotting\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.family'] = 'serif'\n",
                "plt.rcParams['axes.labelsize'] = 12\n",
                "plt.rcParams['axes.titlesize'] = 14\n",
                "\n",
                "# Define colors\n",
                "colors = ['#4C72B0', '#55A868', '#C44E52', '#8172B2', '#CCB974']\n",
                "sns.set_palette(sns.color_palette(colors))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# BigQuery configuration\n",
                "project_id = \"grounded-nebula-408412\"\n",
                "dataset = \"python_src\"\n",
                "\n",
                "# Initialize BigQuery client\n",
                "client = bigquery.Client(project=project_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. BigQuery Utilities\n",
                "\n",
                "This section includes utility functions for working with BigQuery:\n",
                "- List all tables in the dataset\n",
                "- Retrieve the schema of a specific table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "def list_tables():\n",
                "    \"\"\"List all tables in the dataset.\"\"\"\n",
                "    try:\n",
                "        dataset_ref = client.dataset(dataset)\n",
                "        tables = list(client.list_tables(dataset_ref))\n",
                "        table_names = [table.table_id for table in tables]\n",
                "        print(\"Tables in dataset:\")\n",
                "        for table in table_names:\n",
                "            print(f\"- {table}\")\n",
                "    except GoogleCloudError as e:\n",
                "        print(f\"Error listing tables: {str(e)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_table_schema(table_id):\n",
                "    \"\"\"Retrieve the schema of a given BigQuery table.\"\"\"\n",
                "    try:\n",
                "        table_ref = client.dataset(dataset).table(table_id)\n",
                "        table = client.get_table(table_ref)\n",
                "        schema_df = pd.DataFrame([\n",
                "            {\"Column Name\": field.name, \"Data Type\": field.field_type, \"Mode\": field.mode}\n",
                "            for field in table.schema\n",
                "        ])\n",
                "        return schema_df\n",
                "    except GoogleCloudError as e:\n",
                "        print(f\"Error fetching schema: {str(e)}\")\n",
                "        return pd.DataFrame()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example Usage\n",
                "\n",
                "To list all tables in the dataset:\n",
                "```python\n",
                "list_tables()\n",
                "```\n",
                "\n",
                "To get the schema of a specific table:\n",
                "```python\n",
                "get_table_schema('your_table_name')\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Query Execution Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_query(query, use_cache=True):\n",
                "    \"\"\"Execute a BigQuery query and return results as a DataFrame.\"\"\"\n",
                "    try:\n",
                "        # Configure the query job to use cache if requested\n",
                "        job_config = bigquery.QueryJobConfig(use_query_cache=use_cache)\n",
                "\n",
                "        # Execute the query\n",
                "        query_job = client.query(query, job_config=job_config)\n",
                "\n",
                "        # Convert to DataFrame without using the BigQuery Storage API\n",
                "        results_df = query_job.to_dataframe(create_bqstorage_client=False)\n",
                "\n",
                "        # Print information about the results\n",
                "        print(f\"Query executed successfully. Retrieved {len(results_df)} rows.\")\n",
                "        if len(results_df) > 0:\n",
                "            print(f\"Columns: {list(results_df.columns)}\")\n",
                "        else:\n",
                "            print(\"Warning: Query returned no results.\")\n",
                "\n",
                "        return results_df\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"Error executing query: {str(e)}\")\n",
                "        # Return an empty DataFrame so code can continue without errors\n",
                "        return pd.DataFrame()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Network Size Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Query executed successfully. Retrieved 120 rows.\n",
                        "Columns: ['month_start_str', 'node_id', 'toxicity_sent_avg', 'toxicity_received_avg']\n",
                        "\n",
                        "Raw query results:\n",
                        "  month_start_str      node_id  toxicity_sent_avg  toxicity_received_avg\n",
                        "0      2020-01-01          cdu           0.000426               0.141863\n",
                        "1      2020-01-01          csu           0.000396               0.186909\n",
                        "2      2020-01-01  die_gruenen           0.178472               0.097760\n",
                        "3      2020-01-01          fdp           0.018467               0.030446\n",
                        "4      2020-01-01        spdde           0.000517               0.049475\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'party_colors' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[29], line 43\u001b[0m\n\u001b[1;32m     36\u001b[0m party_data \u001b[38;5;241m=\u001b[39m party_df[party_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m party]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m party_data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     38\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m     39\u001b[0m         party_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth_start\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     40\u001b[0m         party_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoxicity_sent_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     41\u001b[0m         marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m         linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m---> 43\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[43mparty_colors\u001b[49m\u001b[38;5;241m.\u001b[39mget(party),\n\u001b[1;32m     44\u001b[0m         label\u001b[38;5;241m=\u001b[39mparty,\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found for party: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparty\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'party_colors' is not defined"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 1200x600 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Query toxicity metrics for specific German political party accounts\n",
                "party_toxicity_query = f\"\"\"\n",
                "SELECT \n",
                "    CAST(month_start AS STRING) as month_start_str,\n",
                "    node_id,\n",
                "    toxicity_sent_avg,\n",
                "    toxicity_received_avg\n",
                "FROM `grounded-nebula-408412.python_src.python_network_users_node_metrics`\n",
                "WHERE node_id IN ('cdu', 'spdde', 'csu', 'fdp', 'die_gruenen')\n",
                "ORDER BY month_start, node_id\n",
                "\"\"\"\n",
                "\n",
                "# Run the query\n",
                "party_df = run_query(party_toxicity_query)\n",
                "\n",
                "# Print the first few rows to debug\n",
                "print(\"\\nRaw query results:\")\n",
                "print(party_df.head())\n",
                "\n",
                "# Define colors for each party\n",
                "party_colors = {\n",
                "    \"cdu\": \"#000000\",  # Black for CDU\n",
                "    \"spdde\": \"#E3000F\",  # Red for SPD\n",
                "    \"csu\": \"#0570C9\",  # Blue for CSU\n",
                "    \"fdp\": \"#FFED00\",  # Yellow for FDP\n",
                "    \"die_gruenen\": \"#1AA037\",  # Green for Die Grünen\n",
                "}\n",
                "\n",
                "# Check if we got data back\n",
                "if len(party_df) == 0:\n",
                "    print(\"No data returned from query. Check permissions and table content.\")\n",
                "else:\n",
                "    # Check if required columns exist\n",
                "    if \"month_start_str\" not in party_df.columns:\n",
                "        print(\n",
                "            f\"Error: 'month_start_str' column not found. Available columns: {list(party_df.columns)}\"\n",
                "        )\n",
                "    else:\n",
                "        # Convert string date to datetime\n",
                "        party_df[\"month_start\"] = pd.to_datetime(party_df[\"month_start_str\"])\n",
                "\n",
                "        # Create figure for toxicity sent\n",
                "        plt.figure(figsize=(12, 6))\n",
                "        for party in [\"cdu\", \"spdde\", \"csu\", \"fdp\", \"die_gruenen\"]:\n",
                "            party_data = party_df[party_df[\"node_id\"] == party]\n",
                "            if not party_data.empty:\n",
                "                plt.plot(\n",
                "                    party_data[\"month_start\"],\n",
                "                    party_data[\"toxicity_sent_avg\"],\n",
                "                    marker=\"o\",\n",
                "                    linewidth=2,\n",
                "                    color=party_colors.get(party),\n",
                "                    label=party,\n",
                "                )\n",
                "            else:\n",
                "                print(f\"No data found for party: {party}\")\n",
                "\n",
                "        plt.title(\"Average Toxicity Sent by German Political Parties\")\n",
                "        plt.xlabel(\"Month\")\n",
                "        plt.ylabel(\"Average Toxicity Sent\")\n",
                "        plt.legend(loc=\"best\")\n",
                "        plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
                "        plt.xticks(rotation=45)\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "\n",
                "        # Create figure for toxicity received\n",
                "        plt.figure(figsize=(12, 6))\n",
                "        for party in [\"cdu\", \"spdde\", \"csu\", \"fdp\", \"die_gruenen\"]:\n",
                "            party_data = party_df[party_df[\"node_id\"] == party]\n",
                "            if not party_data.empty:\n",
                "                plt.plot(\n",
                "                    party_data[\"month_start\"],\n",
                "                    party_data[\"toxicity_received_avg\"],\n",
                "                    marker=\"o\",\n",
                "                    linewidth=2,\n",
                "                    color=party_colors.get(party),\n",
                "                    label=party,\n",
                "                )\n",
                "            else:\n",
                "                print(f\"No data found for party: {party}\")\n",
                "\n",
                "        plt.title(\"Average Toxicity Received by German Political Parties\")\n",
                "        plt.xlabel(\"Month\")\n",
                "        plt.ylabel(\"Average Toxicity Received\")\n",
                "        plt.legend(loc=\"best\")\n",
                "        plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
                "        plt.xticks(rotation=45)\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "\n",
                "        # Optional: Create a combined visualization with subplots\n",
                "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
                "\n",
                "        # Toxicity sent subplot\n",
                "        for party in [\"cdu\", \"spdde\", \"csu\", \"fdp\", \"die_gruenen\"]:\n",
                "            party_data = party_df[party_df[\"node_id\"] == party]\n",
                "            if not party_data.empty:\n",
                "                ax1.plot(\n",
                "                    party_data[\"month_start\"],\n",
                "                    party_data[\"toxicity_sent_avg\"],\n",
                "                    marker=\"o\",\n",
                "                    linewidth=2,\n",
                "                    color=party_colors.get(party),\n",
                "                    label=party,\n",
                "                )\n",
                "\n",
                "        ax1.set_title(\"Average Toxicity Sent by German Political Parties\")\n",
                "        ax1.set_ylabel(\"Average Toxicity\")\n",
                "        ax1.legend(loc=\"best\")\n",
                "        ax1.grid(True, linestyle=\"--\", alpha=0.7)\n",
                "\n",
                "        # Toxicity received subplot\n",
                "        for party in [\"cdu\", \"spdde\", \"csu\", \"fdp\", \"die_gruenen\"]:\n",
                "            party_data = party_df[party_df[\"node_id\"] == party]\n",
                "            if not party_data.empty:\n",
                "                ax2.plot(\n",
                "                    party_data[\"month_start\"],\n",
                "                    party_data[\"toxicity_received_avg\"],\n",
                "                    marker=\"o\",\n",
                "                    linewidth=2,\n",
                "                    color=party_colors.get(party),\n",
                "                    label=party,\n",
                "                )\n",
                "\n",
                "        ax2.set_title(\"Average Toxicity Received by German Political Parties\")\n",
                "        ax2.set_xlabel(\"Month\")\n",
                "        ax2.set_ylabel(\"Average Toxicity\")\n",
                "        ax2.legend(loc=\"best\")\n",
                "        ax2.grid(True, linestyle=\"--\", alpha=0.7)\n",
                "\n",
                "        # Format dates on x-axis\n",
                "        ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
                "        plt.xticks(rotation=45)\n",
                "        plt.tight_layout()\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Current credentials path: /Users/calvindudek/projects/sophie/twitter-analysis-python/.secrets/service-account.json\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "creds_path = os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
                "print(f\"Current credentials path: {creds_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
